{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438fc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import collections \n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, KFold, PredefinedSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from pytimekr import pytimekr\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./train.csv')\n",
    "data.head()\n",
    "\n",
    "plt.rc(\"font\", family=\"AppleGothic\")\n",
    "plt.rcParams['axes.unicode_minus'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item\n",
       "TG    15230\n",
       "BC    13707\n",
       "RD    12184\n",
       "CR    10661\n",
       "CB     7615\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['item'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             0\n",
       "timestamp      0\n",
       "item           0\n",
       "corporation    0\n",
       "location       0\n",
       "supply(kg)     0\n",
       "price(원/kg)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['timestamp'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "# 날짜 --> week와 day column 생성 (day는 요일을 나타냄)\n",
    "\n",
    "data['year'] = data['timestamp'].dt.isocalendar().year\n",
    "data['month'] = data['timestamp'].dt.month\n",
    "data['day'] = data['timestamp'].dt.day\n",
    "data['week'] = data['timestamp'].dt.isocalendar().week\n",
    "\n",
    "data['weekday'] = data['timestamp'].dt.isocalendar().day\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "data_test['timestamp'] = pd.to_datetime(data_test['timestamp'])\n",
    "\n",
    "# 날짜 --> week와 day column 생성 (day는 요일을 나타냄)\n",
    "\n",
    "data_test['year'] = data_test['timestamp'].dt.isocalendar().year\n",
    "data_test['month'] = data_test['timestamp'].dt.month\n",
    "data_test['day'] = data_test['timestamp'].dt.day\n",
    "data_test['week'] = data_test['timestamp'].dt.isocalendar().week\n",
    "\n",
    "data_test['weekday'] = data_test['timestamp'].dt.isocalendar().day\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['isWeekday'] = ((data['weekday'] >= 1) & (data['weekday'] <= 5)).astype(int)\n",
    "data['isSaturday'] = (data['weekday'] == 6).astype(int)\n",
    "data['isSunday'] = (data['weekday'] == 7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['isWeekday'] = ((data_test['weekday'] >= 1) & (data_test['weekday'] <= 5)).astype(int)\n",
    "data_test['isSaturday'] = (data_test['weekday'] == 6).astype(int)\n",
    "data_test['isSunday'] = (data_test['weekday'] == 7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday 삭제 \n",
    "data.drop('weekday', axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.drop('weekday', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item</th>\n",
       "      <th>corporation</th>\n",
       "      <th>location</th>\n",
       "      <th>supply(kg)</th>\n",
       "      <th>price(원/kg)</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>isWeekday</th>\n",
       "      <th>isSaturday</th>\n",
       "      <th>isSunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TG_A_J_20190101</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>TG</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TG_A_J_20190102</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TG</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TG_A_J_20190103</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>TG</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>60601.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TG_A_J_20190104</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>TG</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TG_A_J_20190105</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>TG</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>32352.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59392</th>\n",
       "      <td>RD_F_J_20230227</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>RD</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>452440.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59393</th>\n",
       "      <td>RD_F_J_20230228</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>RD</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>421980.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59394</th>\n",
       "      <td>RD_F_J_20230301</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>RD</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>382980.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59395</th>\n",
       "      <td>RD_F_J_20230302</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>RD</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>477220.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59396</th>\n",
       "      <td>RD_F_J_20230303</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>RD</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>427520.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59397 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  timestamp item corporation location  supply(kg)  \\\n",
       "0      TG_A_J_20190101 2019-01-01   TG           A        J         0.0   \n",
       "1      TG_A_J_20190102 2019-01-02   TG           A        J         0.0   \n",
       "2      TG_A_J_20190103 2019-01-03   TG           A        J     60601.0   \n",
       "3      TG_A_J_20190104 2019-01-04   TG           A        J     25000.0   \n",
       "4      TG_A_J_20190105 2019-01-05   TG           A        J     32352.0   \n",
       "...                ...        ...  ...         ...      ...         ...   \n",
       "59392  RD_F_J_20230227 2023-02-27   RD           F        J    452440.0   \n",
       "59393  RD_F_J_20230228 2023-02-28   RD           F        J    421980.0   \n",
       "59394  RD_F_J_20230301 2023-03-01   RD           F        J    382980.0   \n",
       "59395  RD_F_J_20230302 2023-03-02   RD           F        J    477220.0   \n",
       "59396  RD_F_J_20230303 2023-03-03   RD           F        J    427520.0   \n",
       "\n",
       "       price(원/kg)  year  month  day  week  isWeekday  isSaturday  isSunday  \n",
       "0              0.0  2019      1    1     1          1           0         0  \n",
       "1              0.0  2019      1    2     1          1           0         0  \n",
       "2           1728.0  2019      1    3     1          1           0         0  \n",
       "3           1408.0  2019      1    4     1          1           0         0  \n",
       "4           1250.0  2019      1    5     1          0           1         0  \n",
       "...            ...   ...    ...  ...   ...        ...         ...       ...  \n",
       "59392        468.0  2023      2   27     9          1           0         0  \n",
       "59393        531.0  2023      2   28     9          1           0         0  \n",
       "59394        574.0  2023      3    1     9          1           0         0  \n",
       "59395        523.0  2023      3    2     9          1           0         0  \n",
       "59396        529.0  2023      3    3     9          1           0         0  \n",
       "\n",
       "[59397 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables and scaling\n",
    "categorical_cols = ['item', 'corporation', 'location', 'year','isWeekday','isSaturday','isSunday']\n",
    "numeric_features = ['month', 'day', 'week']\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_train = encoder.fit_transform(data[categorical_cols])\n",
    "encoded_test = encoder.transform(data_test[categorical_cols])\n",
    "\n",
    "# Correcting the column selections by adding a comma between 'day' and 'week'\n",
    "train_features = np.hstack((encoded_train, data[['month', 'day', 'week']].values))\n",
    "test_features = np.hstack((encoded_test, data_test[['month', 'day', 'week']].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_features)\n",
    "\n",
    "# Preparing data for LSTM\n",
    "def create_dataset(dataset, target, look_back=30):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(target[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train_scaled, data['price(원/kg)'].values, look_back)\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[2]))\n",
    "\n",
    "# Define the LSTM model in a function\n",
    "def create_lstm_model(look_back=1, lstm_units=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=(1, look_back)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasRegressor\n",
    "model = KerasRegressor(build_fn=create_lstm_model, verbose=2)\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'look_back': [1, 7, 30, 90],  # Try different look_back values\n",
    "    'lstm_units': [20, 50, 100],  # Try different numbers of LSTM units\n",
    "    'batch_size': [32, 64, 128],  # Try different batch sizes\n",
    "    'epochs': [100, 300 ,500]  # Try different numbers of epochs\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(trainX, trainY)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Use the best model to generate predictions for test data\n",
    "# Ensure to process the test data similar to train data before prediction\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best parameters to train the final model\n",
    "best_params = grid_result.best_params_\n",
    "model = create_lstm_model(look_back=best_params['look_back'], lstm_units=best_params['lstm_units'])\n",
    "model.fit(trainX, trainY, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=2)\n",
    "\n",
    "# Generate predictions for test data\n",
    "test_scaled = scaler.transform(test_features)\n",
    "testX, _ = create_dataset(test_scaled, np.zeros(len(test_features)), best_params['look_back'])\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[2]))\n",
    "test_predictions = model.predict(testX)\n",
    "test_predictions = test_predictions.flatten()\n",
    "\n",
    "# Adjusting the predictions as needed for the submission format\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "if len(test_predictions) == len(sample_submission) - 1:\n",
    "    placeholder = np.array([0])  # or np.mean(test_predictions)\n",
    "    test_predictions = np.insert(test_predictions, 0, placeholder)\n",
    "\n",
    "# Creating the submission DataFrame\n",
    "submission = pd.DataFrame({'ID': data_test['ID'], 'answer': test_predictions})\n",
    "\n",
    "# Adjust predictions where necessary (e.g., setting Sunday prices to 0)\n",
    "submission.loc[data_test['isSunday'] == 1, 'answer'] = 0\n",
    "submission['price(원/kg)'][submission['answer'] < 0] = 0\n",
    "\n",
    "# Saving to a CSV file\n",
    "submission.to_csv('lstm_grid.csv', index=False)\n",
    "\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
